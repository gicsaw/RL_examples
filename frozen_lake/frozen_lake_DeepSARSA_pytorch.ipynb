{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from gym.envs.toy_text.frozen_lake import FrozenLakeEnv\n",
    "env =FrozenLakeEnv(is_slippery=False,map_name=\"4x4\")\n",
    "#env =FrozenLakeEnv(is_slippery=False,map_name=\"8x8\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,para,bias=True):\n",
    "        super(Net,self).__init__()\n",
    "        self.input_dim=para['input_dim']\n",
    "        self.output_dim=para['output_dim']\n",
    "        self.hidden_dim=para['hidden_dim']\n",
    "        \n",
    "        self.w1=Parameter(torch.FloatTensor(self.input_dim,self.hidden_dim))\n",
    "        self.b1=Parameter(torch.FloatTensor(self.hidden_dim))\n",
    "        nn.init.kaiming_normal_(self.w1)\n",
    "#        nn.init.kaiming_uniform_(self.w1)\n",
    "        nn.init.uniform_(self.b1,-0.001,0.001)\n",
    "\n",
    "        self.w2=Parameter(torch.FloatTensor(self.hidden_dim,self.hidden_dim))\n",
    "        self.b2=Parameter(torch.FloatTensor(self.hidden_dim))\n",
    "        nn.init.kaiming_normal_(self.w2)\n",
    "#        nn.init.kaiming_uniform_(self.w2)\n",
    "        nn.init.uniform_(self.b2,-0.001,0.001)\n",
    "        \n",
    "        self.w3=Parameter(torch.FloatTensor(self.hidden_dim,self.hidden_dim))\n",
    "        self.b3=Parameter(torch.FloatTensor(self.hidden_dim))\n",
    "        nn.init.kaiming_normal_(self.w3)\n",
    "#        nn.init.kaiming_uniform_(self.w3)\n",
    "        nn.init.uniform_(self.b3,-0.001,0.001)\n",
    "        \n",
    "        self.w4=Parameter(torch.FloatTensor(self.hidden_dim,self.output_dim))\n",
    "        self.b4=Parameter(torch.FloatTensor(self.output_dim))\n",
    "        nn.init.kaiming_normal_(self.w4)\n",
    "#        nn.init.kaiming_uniform_(self.w4)\n",
    "        nn.init.uniform_(self.b4,-0.001,0.001)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        H=torch.relu( torch.einsum('li,ij->lj',X,self.w1)+self.b1)\n",
    "        H=torch.relu( torch.einsum('li,ij->lj',H,self.w2)+self.b2)\n",
    "        H=torch.relu( torch.einsum('li,ij->lj',H,self.w3)+self.b3)\n",
    "        Y=torch.einsum('li,ij->lj',H,self.w4)+self.b4\n",
    "\n",
    "        return Y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=env.observation_space.n\n",
    "output_dim=env.action_space.n\n",
    "hidden_dim=100\n",
    "\n",
    "para={'input_dim': input_dim, 'output_dim': output_dim, 'hidden_dim': hidden_dim}\n",
    "model=Net(para)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, step: 6, total_reward: -1.060000, epsilon: 0.990000\n",
      "Episode: 1, step: 2, total_reward: -1.020000, epsilon: 0.980100\n",
      "Episode: 2, step: 3, total_reward: -1.030000, epsilon: 0.970299\n",
      "Episode: 3, step: 9, total_reward: -1.090000, epsilon: 0.960596\n",
      "Episode: 4, step: 17, total_reward: -1.170000, epsilon: 0.950990\n",
      "Episode: 5, step: 1, total_reward: -1.010000, epsilon: 0.941480\n",
      "Episode: 6, step: 3, total_reward: -1.030000, epsilon: 0.932065\n",
      "Episode: 7, step: 27, total_reward: -1.270000, epsilon: 0.922745\n",
      "Episode: 8, step: 16, total_reward: -1.160000, epsilon: 0.913517\n",
      "Episode: 9, step: 7, total_reward: -1.070000, epsilon: 0.904382\n",
      "Episode: 10, step: 2, total_reward: -1.020000, epsilon: 0.895338\n",
      "Episode: 11, step: 2, total_reward: -1.020000, epsilon: 0.886385\n",
      "Episode: 12, step: 13, total_reward: -1.130000, epsilon: 0.877521\n",
      "Episode: 13, step: 4, total_reward: -1.040000, epsilon: 0.868746\n",
      "Episode: 14, step: 1, total_reward: -1.010000, epsilon: 0.860058\n",
      "Episode: 15, step: 2, total_reward: -1.020000, epsilon: 0.851458\n",
      "Episode: 16, step: 22, total_reward: -1.220000, epsilon: 0.842943\n",
      "Episode: 17, step: 11, total_reward: -1.110000, epsilon: 0.834514\n",
      "Episode: 18, step: 6, total_reward: -1.060000, epsilon: 0.826169\n",
      "Episode: 19, step: 5, total_reward: -1.050000, epsilon: 0.817907\n",
      "Episode: 20, step: 1, total_reward: -1.010000, epsilon: 0.809728\n",
      "Episode: 21, step: 5, total_reward: -1.050000, epsilon: 0.801631\n",
      "Episode: 22, step: 3, total_reward: -1.030000, epsilon: 0.793614\n",
      "Episode: 23, step: 5, total_reward: -1.050000, epsilon: 0.785678\n",
      "Episode: 24, step: 19, total_reward: -1.190000, epsilon: 0.777821\n",
      "Episode: 25, step: 6, total_reward: -1.060000, epsilon: 0.770043\n",
      "Episode: 26, step: 8, total_reward: -1.080000, epsilon: 0.762343\n",
      "Episode: 27, step: 4, total_reward: -1.040000, epsilon: 0.754719\n",
      "Episode: 28, step: 5, total_reward: -1.050000, epsilon: 0.747172\n",
      "Episode: 29, step: 9, total_reward: -1.090000, epsilon: 0.739700\n",
      "Episode: 30, step: 15, total_reward: -1.150000, epsilon: 0.732303\n",
      "Episode: 31, step: 3, total_reward: -1.030000, epsilon: 0.724980\n",
      "Episode: 32, step: 4, total_reward: -1.040000, epsilon: 0.717731\n",
      "Episode: 33, step: 3, total_reward: -1.030000, epsilon: 0.710553\n",
      "Episode: 34, step: 4, total_reward: -1.040000, epsilon: 0.703448\n",
      "Episode: 35, step: 17, total_reward: 0.830000, epsilon: 0.696413\n",
      "[0, 4, 4, 4, 4, 8, 4, 8, 9, 10, 14, 13, 14, 14, 13, 14, 10, 14, 15]\n",
      "Episode: 36, step: 22, total_reward: -1.220000, epsilon: 0.689449\n",
      "Episode: 37, step: 9, total_reward: -1.090000, epsilon: 0.682555\n",
      "Episode: 38, step: 5, total_reward: -1.050000, epsilon: 0.675729\n",
      "Episode: 39, step: 2, total_reward: -1.020000, epsilon: 0.668972\n",
      "Episode: 40, step: 8, total_reward: -1.080000, epsilon: 0.662282\n",
      "Episode: 41, step: 14, total_reward: -1.140000, epsilon: 0.655659\n",
      "Episode: 42, step: 1, total_reward: -1.010000, epsilon: 0.649103\n",
      "Episode: 43, step: 2, total_reward: -1.020000, epsilon: 0.642612\n",
      "Episode: 44, step: 1, total_reward: -1.010000, epsilon: 0.636185\n",
      "Episode: 45, step: 30, total_reward: -1.300000, epsilon: 0.629824\n",
      "Episode: 46, step: 3, total_reward: -1.030000, epsilon: 0.623525\n",
      "Episode: 47, step: 3, total_reward: -1.030000, epsilon: 0.617290\n",
      "Episode: 48, step: 14, total_reward: -1.140000, epsilon: 0.611117\n",
      "Episode: 49, step: 22, total_reward: -1.220000, epsilon: 0.605006\n",
      "Episode: 50, step: 9, total_reward: -1.090000, epsilon: 0.598956\n",
      "Episode: 51, step: 11, total_reward: -1.110000, epsilon: 0.592966\n",
      "Episode: 52, step: 22, total_reward: -1.220000, epsilon: 0.587037\n",
      "Episode: 53, step: 6, total_reward: -1.060000, epsilon: 0.581166\n",
      "Episode: 54, step: 23, total_reward: -1.230000, epsilon: 0.575355\n",
      "Episode: 55, step: 16, total_reward: -1.160000, epsilon: 0.569601\n",
      "Episode: 56, step: 10, total_reward: -1.100000, epsilon: 0.563905\n",
      "Episode: 57, step: 4, total_reward: -1.040000, epsilon: 0.558266\n",
      "Episode: 58, step: 18, total_reward: -1.180000, epsilon: 0.552683\n",
      "Episode: 59, step: 5, total_reward: -1.050000, epsilon: 0.547157\n",
      "Episode: 60, step: 6, total_reward: 0.940000, epsilon: 0.541685\n",
      "[0, 4, 8, 9, 13, 14, 14, 15]\n",
      "Episode: 61, step: 6, total_reward: 0.940000, epsilon: 0.536268\n",
      "[0, 4, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 62, step: 4, total_reward: -1.040000, epsilon: 0.530906\n",
      "Episode: 63, step: 6, total_reward: -1.060000, epsilon: 0.525596\n",
      "Episode: 64, step: 8, total_reward: -1.080000, epsilon: 0.520341\n",
      "Episode: 65, step: 48, total_reward: -1.480000, epsilon: 0.515137\n",
      "Episode: 66, step: 10, total_reward: -1.100000, epsilon: 0.509986\n",
      "Episode: 67, step: 1, total_reward: -1.010000, epsilon: 0.504886\n",
      "Episode: 68, step: 23, total_reward: -1.230000, epsilon: 0.499837\n",
      "Episode: 69, step: 6, total_reward: -1.060000, epsilon: 0.494839\n",
      "Episode: 70, step: 7, total_reward: 0.930000, epsilon: 0.489890\n",
      "[0, 1, 2, 6, 2, 6, 10, 14, 15]\n",
      "Episode: 71, step: 2, total_reward: -1.020000, epsilon: 0.484991\n",
      "Episode: 72, step: 9, total_reward: -1.090000, epsilon: 0.480141\n",
      "Episode: 73, step: 9, total_reward: 0.910000, epsilon: 0.475340\n",
      "[0, 0, 4, 8, 8, 9, 10, 14, 13, 14, 15]\n",
      "Episode: 74, step: 4, total_reward: -1.040000, epsilon: 0.470587\n",
      "Episode: 75, step: 7, total_reward: -1.070000, epsilon: 0.465881\n",
      "Episode: 76, step: 14, total_reward: 0.860000, epsilon: 0.461222\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 2, 3, 3, 2, 6, 10, 14, 15]\n",
      "Episode: 77, step: 5, total_reward: -1.050000, epsilon: 0.456610\n",
      "Episode: 78, step: 6, total_reward: -1.060000, epsilon: 0.452044\n",
      "Episode: 79, step: 11, total_reward: -1.110000, epsilon: 0.447523\n",
      "Episode: 80, step: 14, total_reward: -1.140000, epsilon: 0.443048\n",
      "Episode: 81, step: 8, total_reward: -1.080000, epsilon: 0.438618\n",
      "Episode: 82, step: 4, total_reward: -1.040000, epsilon: 0.434231\n",
      "Episode: 83, step: 2, total_reward: -1.020000, epsilon: 0.429889\n",
      "Episode: 84, step: 3, total_reward: -1.030000, epsilon: 0.425590\n",
      "Episode: 85, step: 34, total_reward: -1.340000, epsilon: 0.421334\n",
      "Episode: 86, step: 29, total_reward: 0.710000, epsilon: 0.417121\n",
      "[0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 3, 2, 6, 10, 6, 2, 6, 10, 14, 15]\n",
      "Episode: 87, step: 15, total_reward: 0.850000, epsilon: 0.412950\n",
      "[0, 1, 2, 2, 1, 2, 3, 2, 1, 0, 0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 88, step: 7, total_reward: 0.930000, epsilon: 0.408820\n",
      "[0, 0, 1, 2, 2, 6, 10, 14, 15]\n",
      "Episode: 89, step: 11, total_reward: -1.110000, epsilon: 0.404732\n",
      "Episode: 90, step: 13, total_reward: 0.870000, epsilon: 0.400685\n",
      "[0, 4, 8, 8, 8, 8, 8, 8, 4, 8, 8, 9, 10, 14, 15]\n",
      "Episode: 91, step: 6, total_reward: 0.940000, epsilon: 0.396678\n",
      "[0, 0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 92, step: 4, total_reward: -1.040000, epsilon: 0.392711\n",
      "Episode: 93, step: 1, total_reward: -1.010000, epsilon: 0.388784\n",
      "Episode: 94, step: 21, total_reward: 0.790000, epsilon: 0.384896\n",
      "[0, 0, 0, 1, 2, 1, 2, 1, 2, 2, 1, 0, 0, 0, 4, 8, 9, 13, 14, 14, 13, 14, 15]\n",
      "Episode: 95, step: 3, total_reward: -1.030000, epsilon: 0.381047\n",
      "Episode: 96, step: 2, total_reward: -1.020000, epsilon: 0.377237\n",
      "Episode: 97, step: 13, total_reward: 0.870000, epsilon: 0.373464\n",
      "[0, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 13, 14, 15]\n",
      "Episode: 98, step: 14, total_reward: 0.860000, epsilon: 0.369730\n",
      "[0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 99, step: 6, total_reward: -1.060000, epsilon: 0.366032\n",
      "Episode: 100, step: 13, total_reward: -1.130000, epsilon: 0.362372\n",
      "Episode: 101, step: 6, total_reward: 0.940000, epsilon: 0.358748\n",
      "[0, 4, 8, 9, 13, 13, 14, 15]\n",
      "Episode: 102, step: 8, total_reward: 0.920000, epsilon: 0.355161\n",
      "[0, 0, 4, 8, 8, 8, 9, 13, 14, 15]\n",
      "Episode: 103, step: 7, total_reward: 0.930000, epsilon: 0.351609\n",
      "[0, 4, 8, 9, 13, 14, 13, 14, 15]\n",
      "Episode: 104, step: 28, total_reward: 0.720000, epsilon: 0.348093\n",
      "[0, 1, 2, 1, 2, 3, 2, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 6, 10, 14, 15]\n",
      "Episode: 105, step: 6, total_reward: -1.060000, epsilon: 0.344612\n",
      "Episode: 106, step: 7, total_reward: 0.930000, epsilon: 0.341166\n",
      "[0, 1, 2, 6, 2, 6, 10, 14, 15]\n",
      "Episode: 107, step: 2, total_reward: -1.020000, epsilon: 0.337754\n",
      "Episode: 108, step: 1, total_reward: -1.010000, epsilon: 0.334377\n",
      "Episode: 109, step: 8, total_reward: 0.920000, epsilon: 0.331033\n",
      "[0, 4, 4, 8, 9, 13, 14, 10, 14, 15]\n",
      "Episode: 110, step: 3, total_reward: -1.030000, epsilon: 0.327723\n",
      "Episode: 111, step: 5, total_reward: 0.950000, epsilon: 0.324446\n",
      "[0, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 112, step: 6, total_reward: -1.060000, epsilon: 0.321201\n",
      "Episode: 113, step: 5, total_reward: 0.950000, epsilon: 0.317989\n",
      "[0, 1, 2, 6, 10, 14, 15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 114, step: 7, total_reward: 0.930000, epsilon: 0.314809\n",
      "[0, 0, 1, 2, 2, 6, 10, 14, 15]\n",
      "Episode: 115, step: 5, total_reward: 0.950000, epsilon: 0.311661\n",
      "[0, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 116, step: 3, total_reward: -1.030000, epsilon: 0.308544\n",
      "Episode: 117, step: 5, total_reward: -1.050000, epsilon: 0.305459\n",
      "Episode: 118, step: 5, total_reward: 0.950000, epsilon: 0.302404\n",
      "[0, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 119, step: 6, total_reward: -1.060000, epsilon: 0.299380\n",
      "Episode: 120, step: 7, total_reward: -1.070000, epsilon: 0.296387\n",
      "Episode: 121, step: 9, total_reward: 0.910000, epsilon: 0.293423\n",
      "[0, 1, 2, 6, 10, 6, 10, 14, 10, 14, 15]\n",
      "Episode: 122, step: 37, total_reward: 0.630000, epsilon: 0.290488\n",
      "[0, 1, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 1, 2, 6, 2, 2, 6, 2, 6, 2, 6, 10, 14, 15]\n",
      "Episode: 123, step: 18, total_reward: 0.820000, epsilon: 0.287584\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 2, 3, 2, 2, 3, 2, 6, 10, 14, 15]\n",
      "Episode: 124, step: 4, total_reward: -1.040000, epsilon: 0.284708\n",
      "Episode: 125, step: 9, total_reward: 0.910000, epsilon: 0.281861\n",
      "[0, 0, 1, 2, 6, 10, 14, 14, 10, 14, 15]\n",
      "Episode: 126, step: 47, total_reward: 0.530000, epsilon: 0.279042\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 13, 14, 15]\n",
      "Episode: 127, step: 3, total_reward: -1.030000, epsilon: 0.276252\n",
      "Episode: 128, step: 5, total_reward: 0.950000, epsilon: 0.273489\n",
      "[0, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 129, step: 5, total_reward: 0.950000, epsilon: 0.270754\n",
      "[0, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 130, step: 25, total_reward: 0.750000, epsilon: 0.268047\n",
      "[0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 131, step: 67, total_reward: 0.330000, epsilon: 0.265366\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 3, 2, 1, 1, 2, 1, 2, 2, 2, 6, 10, 14, 13, 14, 15]\n",
      "Episode: 132, step: 3, total_reward: -1.030000, epsilon: 0.262713\n",
      "Episode: 133, step: 50, total_reward: -1.500000, epsilon: 0.260085\n",
      "Episode: 134, step: 51, total_reward: 0.490000, epsilon: 0.257485\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 1, 2, 1, 2, 6, 10, 14, 15]\n",
      "Episode: 135, step: 7, total_reward: 0.930000, epsilon: 0.254910\n",
      "[0, 4, 8, 9, 13, 9, 13, 14, 15]\n",
      "Episode: 136, step: 5, total_reward: 0.950000, epsilon: 0.252361\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 137, step: 3, total_reward: -1.030000, epsilon: 0.249837\n",
      "Episode: 138, step: 18, total_reward: 0.820000, epsilon: 0.247339\n",
      "[0, 0, 4, 8, 9, 13, 14, 13, 14, 10, 9, 13, 14, 10, 14, 10, 14, 10, 14, 15]\n",
      "Episode: 139, step: 1, total_reward: -1.010000, epsilon: 0.244865\n",
      "Episode: 140, step: 3, total_reward: -1.030000, epsilon: 0.242417\n",
      "Episode: 141, step: 7, total_reward: -1.070000, epsilon: 0.239992\n",
      "Episode: 142, step: 13, total_reward: -1.130000, epsilon: 0.237593\n",
      "Episode: 143, step: 20, total_reward: -1.200000, epsilon: 0.235217\n",
      "Episode: 144, step: 16, total_reward: -1.160000, epsilon: 0.232864\n",
      "Episode: 145, step: 2, total_reward: -1.020000, epsilon: 0.230536\n",
      "Episode: 146, step: 5, total_reward: 0.950000, epsilon: 0.228230\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 147, step: 13, total_reward: 0.870000, epsilon: 0.225948\n",
      "[0, 4, 4, 4, 4, 0, 4, 0, 4, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 148, step: 3, total_reward: -1.030000, epsilon: 0.223689\n",
      "Episode: 149, step: 5, total_reward: 0.950000, epsilon: 0.221452\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 150, step: 1, total_reward: -1.010000, epsilon: 0.219237\n",
      "Episode: 151, step: 1, total_reward: -1.010000, epsilon: 0.217045\n",
      "Episode: 152, step: 7, total_reward: 0.930000, epsilon: 0.214874\n",
      "[0, 4, 8, 9, 13, 14, 13, 14, 15]\n",
      "Episode: 153, step: 5, total_reward: 0.950000, epsilon: 0.212726\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 154, step: 5, total_reward: 0.950000, epsilon: 0.210598\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 155, step: 5, total_reward: 0.950000, epsilon: 0.208492\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 156, step: 7, total_reward: 0.930000, epsilon: 0.206408\n",
      "[0, 4, 8, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 157, step: 6, total_reward: 0.940000, epsilon: 0.204343\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 158, step: 2, total_reward: -1.020000, epsilon: 0.202300\n",
      "Episode: 159, step: 6, total_reward: 0.940000, epsilon: 0.200277\n",
      "[0, 4, 8, 8, 9, 13, 14, 15]\n",
      "Episode: 160, step: 20, total_reward: 0.800000, epsilon: 0.198274\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 8, 9, 13, 14, 14, 15]\n",
      "Episode: 161, step: 1, total_reward: -1.010000, epsilon: 0.196292\n",
      "Episode: 162, step: 12, total_reward: 0.880000, epsilon: 0.194329\n",
      "[0, 0, 0, 0, 0, 0, 4, 8, 9, 8, 9, 13, 14, 15]\n",
      "Episode: 163, step: 6, total_reward: 0.940000, epsilon: 0.192385\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 164, step: 5, total_reward: 0.950000, epsilon: 0.190461\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 165, step: 3, total_reward: -1.030000, epsilon: 0.188557\n",
      "Episode: 166, step: 5, total_reward: 0.950000, epsilon: 0.186671\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 167, step: 2, total_reward: -1.020000, epsilon: 0.184805\n",
      "Episode: 168, step: 7, total_reward: 0.930000, epsilon: 0.182957\n",
      "[0, 4, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 169, step: 3, total_reward: -1.030000, epsilon: 0.181127\n",
      "Episode: 170, step: 5, total_reward: 0.950000, epsilon: 0.179316\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 171, step: 5, total_reward: 0.950000, epsilon: 0.177523\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 172, step: 5, total_reward: 0.950000, epsilon: 0.175747\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 173, step: 5, total_reward: 0.950000, epsilon: 0.173990\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 174, step: 5, total_reward: 0.950000, epsilon: 0.172250\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 175, step: 5, total_reward: 0.950000, epsilon: 0.170527\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 176, step: 7, total_reward: 0.930000, epsilon: 0.168822\n",
      "[0, 4, 8, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 177, step: 7, total_reward: 0.930000, epsilon: 0.167134\n",
      "[0, 4, 8, 9, 13, 9, 13, 14, 15]\n",
      "Episode: 178, step: 6, total_reward: 0.940000, epsilon: 0.165463\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 179, step: 5, total_reward: 0.950000, epsilon: 0.163808\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 180, step: 6, total_reward: 0.940000, epsilon: 0.162170\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 181, step: 6, total_reward: 0.940000, epsilon: 0.160548\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 182, step: 15, total_reward: 0.850000, epsilon: 0.158943\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 183, step: 6, total_reward: 0.940000, epsilon: 0.157353\n",
      "[0, 4, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 184, step: 27, total_reward: 0.730000, epsilon: 0.155780\n",
      "[0, 4, 8, 9, 13, 9, 13, 9, 13, 9, 13, 9, 10, 9, 13, 9, 13, 9, 13, 9, 13, 9, 13, 9, 13, 14, 10, 14, 15]\n",
      "Episode: 185, step: 29, total_reward: -1.290000, epsilon: 0.154222\n",
      "Episode: 186, step: 6, total_reward: 0.940000, epsilon: 0.152680\n",
      "[0, 4, 8, 9, 13, 13, 14, 15]\n",
      "Episode: 187, step: 7, total_reward: 0.930000, epsilon: 0.151153\n",
      "[0, 4, 8, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 188, step: 21, total_reward: 0.790000, epsilon: 0.149641\n",
      "[0, 4, 8, 9, 13, 14, 13, 14, 13, 14, 13, 14, 13, 9, 13, 14, 13, 14, 13, 14, 13, 14, 15]\n",
      "Episode: 189, step: 5, total_reward: 0.950000, epsilon: 0.148145\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 190, step: 5, total_reward: 0.950000, epsilon: 0.146664\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 191, step: 5, total_reward: 0.950000, epsilon: 0.145197\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 192, step: 5, total_reward: 0.950000, epsilon: 0.143745\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 193, step: 4, total_reward: -1.040000, epsilon: 0.142307\n",
      "Episode: 194, step: 9, total_reward: 0.910000, epsilon: 0.140884\n",
      "[0, 4, 8, 9, 13, 13, 9, 10, 14, 14, 15]\n",
      "Episode: 195, step: 20, total_reward: 0.800000, epsilon: 0.139476\n",
      "[0, 4, 8, 9, 13, 9, 13, 13, 13, 13, 13, 13, 13, 13, 9, 13, 13, 13, 13, 13, 14, 15]\n",
      "Episode: 196, step: 5, total_reward: 0.950000, epsilon: 0.138081\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 197, step: 2, total_reward: -1.020000, epsilon: 0.136700\n",
      "Episode: 198, step: 5, total_reward: 0.950000, epsilon: 0.135333\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 199, step: 7, total_reward: 0.930000, epsilon: 0.133980\n",
      "[0, 4, 8, 9, 10, 9, 13, 14, 15]\n",
      "Episode: 200, step: 10, total_reward: 0.900000, epsilon: 0.132640\n",
      "[0, 0, 4, 0, 4, 8, 9, 13, 9, 13, 14, 15]\n",
      "Episode: 201, step: 5, total_reward: 0.950000, epsilon: 0.131313\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 202, step: 7, total_reward: 0.930000, epsilon: 0.130000\n",
      "[0, 4, 8, 9, 13, 14, 10, 14, 15]\n",
      "Episode: 203, step: 7, total_reward: 0.930000, epsilon: 0.128700\n",
      "[0, 1, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 204, step: 5, total_reward: 0.950000, epsilon: 0.127413\n",
      "[0, 4, 8, 9, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 205, step: 44, total_reward: -1.440000, epsilon: 0.126139\n",
      "Episode: 206, step: 7, total_reward: 0.930000, epsilon: 0.124878\n",
      "[0, 4, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 207, step: 44, total_reward: -1.440000, epsilon: 0.123629\n",
      "Episode: 208, step: 1, total_reward: -1.010000, epsilon: 0.122393\n",
      "Episode: 209, step: 90, total_reward: 0.100000, epsilon: 0.121169\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 210, step: 5, total_reward: 0.950000, epsilon: 0.119957\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 211, step: 7, total_reward: 0.930000, epsilon: 0.118758\n",
      "[0, 4, 8, 9, 13, 14, 10, 14, 15]\n",
      "Episode: 212, step: 5, total_reward: 0.950000, epsilon: 0.117570\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 213, step: 5, total_reward: 0.950000, epsilon: 0.116394\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 214, step: 7, total_reward: 0.930000, epsilon: 0.115230\n",
      "[0, 0, 4, 8, 9, 13, 13, 14, 15]\n",
      "Episode: 215, step: 5, total_reward: 0.950000, epsilon: 0.114078\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 216, step: 5, total_reward: 0.950000, epsilon: 0.112937\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 217, step: 5, total_reward: 0.950000, epsilon: 0.111808\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 218, step: 5, total_reward: 0.950000, epsilon: 0.110690\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 219, step: 5, total_reward: 0.950000, epsilon: 0.109583\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 220, step: 5, total_reward: 0.950000, epsilon: 0.108487\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 221, step: 6, total_reward: 0.940000, epsilon: 0.107402\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 222, step: 6, total_reward: 0.940000, epsilon: 0.106328\n",
      "[0, 4, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 223, step: 5, total_reward: 0.950000, epsilon: 0.105265\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 224, step: 5, total_reward: 0.950000, epsilon: 0.104212\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 225, step: 7, total_reward: 0.930000, epsilon: 0.103170\n",
      "[0, 4, 8, 9, 13, 14, 13, 14, 15]\n",
      "Episode: 226, step: 5, total_reward: 0.950000, epsilon: 0.102138\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 227, step: 5, total_reward: 0.950000, epsilon: 0.101117\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 228, step: 6, total_reward: 0.940000, epsilon: 0.100106\n",
      "[0, 4, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 229, step: 5, total_reward: 0.950000, epsilon: 0.099105\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 230, step: 7, total_reward: 0.930000, epsilon: 0.098114\n",
      "[0, 4, 8, 9, 8, 9, 13, 14, 15]\n",
      "Episode: 231, step: 26, total_reward: -1.260000, epsilon: 0.097133\n",
      "Episode: 232, step: 15, total_reward: 0.850000, epsilon: 0.096161\n",
      "[0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 233, step: 13, total_reward: 0.870000, epsilon: 0.095200\n",
      "[0, 4, 8, 9, 13, 9, 13, 9, 13, 9, 13, 14, 13, 14, 15]\n",
      "Episode: 234, step: 5, total_reward: 0.950000, epsilon: 0.094248\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 235, step: 5, total_reward: 0.950000, epsilon: 0.093305\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 236, step: 5, total_reward: 0.950000, epsilon: 0.092372\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 237, step: 5, total_reward: 0.950000, epsilon: 0.091448\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 238, step: 5, total_reward: 0.950000, epsilon: 0.090534\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 239, step: 5, total_reward: 0.950000, epsilon: 0.089629\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 240, step: 5, total_reward: 0.950000, epsilon: 0.088732\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 241, step: 5, total_reward: 0.950000, epsilon: 0.087845\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 242, step: 5, total_reward: 0.950000, epsilon: 0.086967\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 243, step: 3, total_reward: -1.030000, epsilon: 0.086097\n",
      "Episode: 244, step: 35, total_reward: 0.650000, epsilon: 0.085236\n",
      "[0, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 245, step: 7, total_reward: 0.930000, epsilon: 0.084384\n",
      "[0, 4, 8, 9, 13, 13, 13, 14, 15]\n",
      "Episode: 246, step: 5, total_reward: 0.950000, epsilon: 0.083540\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 247, step: 7, total_reward: 0.930000, epsilon: 0.082704\n",
      "[0, 4, 4, 8, 9, 13, 14, 14, 15]\n",
      "Episode: 248, step: 68, total_reward: 0.320000, epsilon: 0.081877\n",
      "[0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 4, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 249, step: 5, total_reward: 0.950000, epsilon: 0.081059\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 250, step: 6, total_reward: 0.940000, epsilon: 0.080248\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 251, step: 6, total_reward: 0.940000, epsilon: 0.079445\n",
      "[0, 0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 252, step: 5, total_reward: 0.950000, epsilon: 0.078651\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 253, step: 5, total_reward: 0.950000, epsilon: 0.077864\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 254, step: 13, total_reward: 0.870000, epsilon: 0.077086\n",
      "[0, 4, 8, 9, 13, 9, 8, 9, 13, 13, 13, 13, 13, 14, 15]\n",
      "Episode: 255, step: 8, total_reward: 0.920000, epsilon: 0.076315\n",
      "[0, 4, 8, 9, 13, 13, 13, 13, 14, 15]\n",
      "Episode: 256, step: 7, total_reward: -1.070000, epsilon: 0.075552\n",
      "Episode: 257, step: 5, total_reward: 0.950000, epsilon: 0.074796\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 258, step: 13, total_reward: 0.870000, epsilon: 0.074048\n",
      "[0, 4, 8, 9, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15]\n",
      "Episode: 259, step: 14, total_reward: -1.140000, epsilon: 0.073308\n",
      "Episode: 260, step: 5, total_reward: 0.950000, epsilon: 0.072575\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 261, step: 5, total_reward: 0.950000, epsilon: 0.071849\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 262, step: 5, total_reward: 0.950000, epsilon: 0.071131\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 263, step: 5, total_reward: 0.950000, epsilon: 0.070419\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 264, step: 5, total_reward: 0.950000, epsilon: 0.069715\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 265, step: 5, total_reward: 0.950000, epsilon: 0.069018\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 266, step: 5, total_reward: 0.950000, epsilon: 0.068328\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 267, step: 5, total_reward: 0.950000, epsilon: 0.067644\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 268, step: 5, total_reward: 0.950000, epsilon: 0.066968\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 269, step: 6, total_reward: 0.940000, epsilon: 0.066298\n",
      "[0, 4, 8, 9, 13, 14, 14, 15]\n",
      "Episode: 270, step: 5, total_reward: 0.950000, epsilon: 0.065635\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 271, step: 7, total_reward: 0.930000, epsilon: 0.064979\n",
      "[0, 4, 8, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 272, step: 5, total_reward: 0.950000, epsilon: 0.064329\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 273, step: 5, total_reward: 0.950000, epsilon: 0.063686\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 274, step: 5, total_reward: 0.950000, epsilon: 0.063049\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 275, step: 5, total_reward: 0.950000, epsilon: 0.062419\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 276, step: 5, total_reward: 0.950000, epsilon: 0.061794\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 277, step: 5, total_reward: 0.950000, epsilon: 0.061176\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 278, step: 5, total_reward: 0.950000, epsilon: 0.060565\n",
      "[0, 4, 8, 9, 13, 14, 15]\n",
      "Episode: 279, step: 9, total_reward: 0.910000, epsilon: 0.059959\n",
      "[0, 4, 8, 9, 10, 9, 10, 9, 10, 14, 15]\n",
      "Episode: 280, step: 5, total_reward: 0.950000, epsilon: 0.059359\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 281, step: 5, total_reward: 0.950000, epsilon: 0.058766\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 282, step: 5, total_reward: 0.950000, epsilon: 0.058178\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 283, step: 5, total_reward: 0.950000, epsilon: 0.057596\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 284, step: 5, total_reward: 0.950000, epsilon: 0.057020\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 285, step: 5, total_reward: 0.950000, epsilon: 0.056450\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 286, step: 7, total_reward: 0.930000, epsilon: 0.055886\n",
      "[0, 4, 8, 9, 8, 9, 10, 14, 15]\n",
      "Episode: 287, step: 7, total_reward: 0.930000, epsilon: 0.055327\n",
      "[0, 4, 0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 288, step: 5, total_reward: 0.950000, epsilon: 0.054774\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 289, step: 5, total_reward: 0.950000, epsilon: 0.054226\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 290, step: 5, total_reward: 0.950000, epsilon: 0.053684\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 291, step: 5, total_reward: 0.950000, epsilon: 0.053147\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 292, step: 3, total_reward: -1.030000, epsilon: 0.052615\n",
      "Episode: 293, step: 5, total_reward: 0.950000, epsilon: 0.052089\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 294, step: 5, total_reward: 0.950000, epsilon: 0.051568\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 295, step: 5, total_reward: 0.950000, epsilon: 0.051053\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 296, step: 5, total_reward: 0.950000, epsilon: 0.050542\n",
      "[0, 4, 8, 9, 10, 14, 15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 297, step: 5, total_reward: 0.950000, epsilon: 0.050037\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 298, step: 5, total_reward: 0.950000, epsilon: 0.049536\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "Episode: 299, step: 5, total_reward: 0.950000, epsilon: 0.049041\n",
      "[0, 4, 8, 9, 10, 14, 15]\n",
      "min step:  5 min step episode 111\n",
      "shortest path:  [0, 1, 2, 6, 10, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "max_episodes=300\n",
    "max_step=100\n",
    "lr=0.001\n",
    "lr2=1.0\n",
    "gamma=0.99\n",
    "epsilon0 = 1.0\n",
    "\n",
    "\n",
    "# initialize\n",
    "\n",
    "epsilon=epsilon0\n",
    "min_step=max_step\n",
    "min_step_episode=max_episodes\n",
    "min_step_path=[]\n",
    "for episode in range(max_episodes):\n",
    "    epsilon=epsilon*0.99\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    state_list = [state]\n",
    "    win=0\n",
    "\n",
    "    for step in range(0,max_step):\n",
    "        state_m=np.zeros([1,env.observation_space.n],dtype=np.float32)\n",
    "        state_m[0][state]=1.0\n",
    "        state_m_torch=Variable(torch.from_numpy(state_m))\n",
    "        Q_pred=model(state_m_torch)\n",
    "        Q_pred=Q_pred.cpu().detach().numpy()\n",
    "        if np.random.rand()>epsilon :\n",
    "            action=np.argmax(Q_pred[0])\n",
    "        else:\n",
    "            action=np.random.choice(env.action_space.n)\n",
    "\n",
    "        state_next,reward,game_over,_ = env.step(action)\n",
    "        \n",
    "        if reward==0 : \n",
    "            reward=-0.01\n",
    "        if reward!=1.0 and game_over==1:\n",
    "            reward=-1.0\n",
    "            \n",
    "        state_m_next=np.zeros([1,env.observation_space.n],dtype=np.float32)\n",
    "        state_m_next[0][state_next]=1.0\n",
    "    \n",
    "        state_m_next_torch=Variable(torch.from_numpy(state_m_next))\n",
    "        Q_pred_next=model(state_m_next_torch)\n",
    "        Q_pred_next=Q_pred_next.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        if np.random.rand()>epsilon :\n",
    "            action_next=np.argmax(Q_pred_next[0])\n",
    "        else:\n",
    "            action_next=np.random.choice(env.action_space.n)\n",
    "\n",
    "        Y_true=copy.deepcopy(Q_pred[0])\n",
    "\n",
    "        if reward==1.0 and game_over==1:\n",
    "            Y_true[action]= reward\n",
    "        else :\n",
    "            Y_true[action]=reward+gamma* (Q_pred_next[0][action_next])\n",
    "        Y_true=np.reshape(Y_true,[1,env.action_space.n])\n",
    "        for j in range(0,1):\n",
    "            optimizer.zero_grad()\n",
    "            state_m_torch=Variable(torch.from_numpy(state_m))\n",
    "            Y_pred=model(state_m_torch)\n",
    "            Y_true_torch=torch.from_numpy(Y_true)\n",
    "#            print(Y_pred,Y_true_torch)\n",
    "#            print(Y_pred.shape,Y_true_torch.shape)\n",
    "            loss=criterion(Y_pred,Y_true_torch)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            cost=loss.data\n",
    "#            print(cost)\n",
    "            \n",
    "\n",
    "        state=state_next\n",
    "\n",
    "        total_reward=total_reward+reward\n",
    "        state_list.append(state)\n",
    "        if game_over and reward==1:\n",
    "            win=1\n",
    "            if step< min_step:\n",
    "                min_step=step\n",
    "                min_step_path=state_list\n",
    "                min_step_episode=episode\n",
    "        if game_over==1:\n",
    "            break\n",
    "\n",
    "\n",
    "    line_out=\"Episode: %d, step: %d, total_reward: %f, epsilon: %f\" %(episode, step, total_reward,epsilon)\n",
    "    print(line_out)\n",
    "    if reward==1 :\n",
    "        print(state_list)\n",
    "print( \"min step: \", min_step, \"min step episode\", min_step_episode)\n",
    "print(\"shortest path: \", min_step_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "[[-1.0459996  -1.0604872  -1.0491861  -1.0497097 ]\n",
      " [-1.0421464  -1.086665   -1.0567379  -1.0561626 ]\n",
      " [-1.0516323  -1.1133238  -1.0788728  -1.0608284 ]\n",
      " [-1.0758016  -1.1443727  -1.0994091  -1.0534861 ]\n",
      " [-1.0638142  -1.1552012  -1.1362579  -1.0982205 ]\n",
      " [-1.0353754  -1.3108914  -1.1206791  -1.0270288 ]\n",
      " [-1.0922614  -1.2472193  -1.1703107  -1.0898064 ]\n",
      " [-1.0888352  -1.2299815  -1.1160078  -1.0590338 ]\n",
      " [-1.037973   -1.0792972  -1.0525484  -1.0419304 ]\n",
      " [-1.0615772  -1.1182106  -1.0807985  -1.0442165 ]\n",
      " [-1.0476023  -1.1782326  -1.1085908  -1.0214463 ]\n",
      " [-0.9677133  -1.8786765  -1.2827076  -1.0443547 ]\n",
      " [-1.0474529  -1.2051544  -1.2002698  -1.0542508 ]\n",
      " [-1.0881368  -1.3156201  -1.1192148  -1.0242763 ]\n",
      " [-1.1503674  -1.2902833  -1.2034274  -1.1039988 ]\n",
      " [-1.101126   -1.2671618  -1.1716375  -1.0363016 ]\n",
      " [-1.0636882  -1.2337697  -1.1320882  -1.0339714 ]\n",
      " [-1.0530088  -1.236959   -1.140699   -1.0162456 ]\n",
      " [-1.1904857  -1.5811594  -1.5599856  -1.2984487 ]\n",
      " [-1.0872067  -1.2580776  -1.0948609  -1.0708036 ]\n",
      " [-1.1148989  -1.3420031  -1.1721766  -1.0643512 ]\n",
      " [-0.9000939  -2.286607   -1.4397657  -1.0040287 ]\n",
      " [-1.0872234  -1.2314061  -1.1402062  -1.0607193 ]\n",
      " [-1.0379257  -1.2651974  -1.1964415  -1.0640879 ]\n",
      " [-1.051834   -1.2001363  -1.1112252  -1.038764  ]\n",
      " [-1.0808465  -1.2425916  -1.1315638  -1.0419093 ]\n",
      " [-0.94863504 -1.3983268  -1.3196005  -1.1027527 ]\n",
      " [-0.9921757  -1.6475626  -1.3045315  -1.1153731 ]\n",
      " [-1.1026     -1.4068189  -1.2854657  -1.1207079 ]\n",
      " [-1.0297642  -1.2682847  -1.1176528  -1.0156994 ]\n",
      " [-1.0152845  -1.4832326  -1.0902241  -1.0365303 ]\n",
      " [-0.91358006 -1.3709328  -1.0910985  -1.017183  ]\n",
      " [-1.073565   -1.3172551  -1.1046268  -1.0477026 ]\n",
      " [-1.0237988  -2.667606   -1.4220557  -1.2107551 ]\n",
      " [-1.209291   -2.1449542  -1.412383   -1.2047585 ]\n",
      " [-1.0581844  -1.282327   -1.1187581  -1.0454563 ]\n",
      " [-1.0427079  -1.4655466  -1.1362357  -1.0500287 ]\n",
      " [-0.8823322  -1.5669134  -1.209632   -1.0212371 ]\n",
      " [-1.0973268  -1.3963804  -1.1564485  -1.043552  ]\n",
      " [-1.0811415  -1.3204968  -1.1301117  -0.95995474]\n",
      " [-1.1551344  -1.6594094  -1.5477436  -1.0458461 ]\n",
      " [-1.0775901  -1.3932301  -1.1889626  -1.0308491 ]\n",
      " [-1.1101031  -1.522798   -1.2594991  -1.0110718 ]\n",
      " [-1.1195629  -1.5372336  -1.2753735  -1.1324234 ]\n",
      " [-1.0725946  -1.6982641  -1.3515171  -1.0763143 ]\n",
      " [-0.98296255 -1.7716085  -1.1945714  -0.99228203]\n",
      " [-1.0629952  -1.4402007  -1.1780839  -1.0028638 ]\n",
      " [-1.0560429  -1.1638619  -1.0985441  -1.0609089 ]\n",
      " [-1.0492213  -1.2438612  -1.1882037  -1.044343  ]\n",
      " [-1.0687649  -1.3101877  -1.1334441  -1.0601028 ]\n",
      " [-1.0492308  -1.4167506  -1.1431592  -1.093459  ]\n",
      " [-1.0586579  -1.3472335  -1.0808326  -1.0384182 ]\n",
      " [-1.066348   -1.0740504  -1.0779039  -1.0804698 ]\n",
      " [-0.9917506  -1.4693378  -1.1913058  -1.0258064 ]\n",
      " [-0.9192036  -1.7372828  -1.1738143  -0.9353937 ]\n",
      " [-1.103569   -1.3451527  -1.153088   -1.0335511 ]\n",
      " [-1.1364521  -1.4369217  -1.1235034  -1.0524793 ]\n",
      " [-1.0303516  -1.433154   -1.1641836  -1.0195279 ]\n",
      " [-0.9872523  -1.9526846  -1.4838978  -1.1414226 ]\n",
      " [-1.0805403  -1.2608725  -1.1513085  -1.0627239 ]\n",
      " [-1.1086668  -1.2109987  -1.120112   -1.0665593 ]\n",
      " [-1.0634844  -1.2711973  -1.1089872  -1.0532855 ]\n",
      " [-1.1920731  -1.3261286  -1.2837266  -1.1598303 ]\n",
      " [-1.0761143  -1.3615698  -1.1647918  -1.0561348 ]]\n"
     ]
    }
   ],
   "source": [
    "#state=np.arange(0,15)\n",
    "#sess.run(init)\n",
    "state_m=np.zeros([input_dim,env.observation_space.n],dtype=np.float32)\n",
    "for i in range(0,input_dim):\n",
    "    state_m[i][i]=1.0\n",
    "print(state_m)\n",
    "state_m_torch=Variable(torch.from_numpy(state_m))\n",
    "Q_pred=model(state_m_torch)\n",
    "Q_pred=Q_pred.cpu().detach().numpy()\n",
    "print(Q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
